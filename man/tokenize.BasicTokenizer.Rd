% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenization.R
\name{tokenize.BasicTokenizer}
\alias{tokenize.BasicTokenizer}
\title{Tokenizer method for objects of BasicTokenizer class.}
\usage{
\method{tokenize}{BasicTokenizer}(b_tokenizer, text)
}
\arguments{
\item{b_tokenizer}{the BasicTokenizer object to apply.}

\item{text}{The text to tokenize.}
}
\value{
A character vector of wordpiece tokens.
}
\description{
This tokenizer performs some basic cleaning, then splits up text
on whitespace and punctuation.
}
\examples{
\dontrun{
b_tokenizer <- BasicTokenizer(TRUE)
tokenize(b_tokenizer, text = "a bunch of words")
}
}
